default_provider: groq

providers:
  groq:
    model:
      name: llama-3.1-8b-instant
      temperature: 0.3
      max_tokens: 1024
    request:
      timeout: 30
      retries: 2

  openai:
    model:
      name: gpt-4o-mini
      temperature: 0.2
      max_tokens: 1024
    request:
      timeout: 30
      retries: 2
